
services:
  zookeeper:
    image: confluentinc/cp-zookeeper:7.3.0
    container_name: zookeeper
    ports:
      - "2181:2181"
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000

  kafka:
    image: confluentinc/cp-kafka:7.3.0
    container_name: kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
    volumes:
      - ../scripts/kafka:/scripts
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 3

  
  kafka-init:
    image: confluentinc/cp-kafka:7.3.0
    depends_on:
      kafka:
        condition: service_healthy
    volumes:
      - ../scripts/kafka:/scripts
    command: /scripts/init-topics.sh

  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181

  
  spark-master:
    image: bitnami/spark:3.3.2
    container_name: spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_DRIVER_MEMORY=2g
      - SPARK_EXECUTOR_MEMORY=2g
    ports:
      - "8081:8080"  # Web UI
      - "7077:7077"  # Master port
      - "4040:4040"  # Spark application UI
    volumes:
      - ../scripts/spark:/opt/spark-apps
      - ../data:/opt/spark-data
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080"]
      interval: 5s
      timeout: 3s
      retries: 3
    networks:
      - text-mining-network

  spark-worker-1:
    image: bitnami/spark:3.3.2
    container_name: spark-worker-1
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ../scripts/spark:/opt/spark-apps
      - ../data:/opt/spark-data
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      - text-mining-network

  spark-worker-2:
    image: bitnami/spark:3.3.2
    container_name: spark-worker-2
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2g
      - SPARK_WORKER_CORES=2
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    volumes:
      - ../scripts/spark:/opt/spark-apps
      - ../data:/opt/spark-data
      - ./spark-defaults.conf:/opt/bitnami/spark/conf/spark-defaults.conf
    depends_on:
      spark-master:
        condition: service_healthy
    networks:
      - text-mining-network

  s3-init:
    image: amazon/aws-cli:latest
    environment:
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_REGION=${AWS_REGION}
    command: >
      /bin/sh -c "
        aws s3api create-bucket --bucket ${S3_RAW_BUCKET} --region ${AWS_REGION} || true;
        aws s3api create-bucket --bucket ${S3_PROCESSED_BUCKET} --region ${AWS_REGION} || true;
        aws s3api create-bucket --bucket ${S3_MODELS_BUCKET} --region ${AWS_REGION} || true;
      "
  
  tensorflow-serving:
    image: tensorflow/serving:latest
    container_name: tf-serving
    ports:
      - "8501:8501"  # REST API
      - "8500:8500"  # gRPC
    volumes:
      - ../models:/models
    environment:
      - MODEL_NAME=text_classifier
      - MODEL_BASE_PATH=/models/text_classifier
      - TENSORFLOW_INTER_OP_PARALLELISM=4
      - TENSORFLOW_INTRA_OP_PARALLELISM=4
    command: 
      - "--model_config_file=/models/models.config"
      - "--monitoring_config_file=/models/monitoring.config"
      - "--enable_batching=true"
      - "--rest_api_timeout_in_ms=30000"
      - "--tensorflow_session_parallelism=4"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8501/v1/models/text_classifier"]
      interval: 30s
      timeout: 10s
      retries: 3
    networks:
      - text-mining-network

  tensorflow-serving-proxy:
    image: nginx:alpine
    container_name: tf-proxy
    ports:
      - "8502:80"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      tensorflow-serving:
        condition: service_healthy
    networks:
      - text-mining-network

  
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/usr/share/prometheus/console_libraries'
      - '--web.console.templates=/usr/share/prometheus/consoles'
    networks:
      - text-mining-network

  grafana:
    image: grafana/grafana:latest
    container_name: grafana
    ports:
      - "3000:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_SECURITY_ADMIN_USER=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    volumes:
      - ./grafana/provisioning:/etc/grafana/provisioning
      - grafana_data:/var/lib/grafana
    depends_on:
      - prometheus
    networks:
      - text-mining-network

networks:
  text-mining-network:
    driver: bridge

volumes:
  prometheus_data:
  grafana_data:
  kafka_data:
  spark_data:
  model_data: